{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNlvvQWSN1G3NiI5OfjZYdU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install fancyimpute"],"metadata":{"id":"wcYfQzYOEeSZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zw9nC7xLCrGq"},"outputs":[],"source":["import pandas as pd\n","from sklearn.decomposition import PCA\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.ensemble import RandomForestClassifier\n","import lightgbm as lgb\n","from sklearn.metrics import accuracy_score\n","import pickle\n","from fancyimpute import IterativeImputer\n","import matplotlib.pyplot as plt\n","\n","# Load the data and select columns\n","\n","columns_to_select = [\n","    'Distance', 'Last Finish pos', 'Last-1 Finish pos', 'Weight', 'Wins', 'Places',\n","    'win%', 'Place%', 'Course Wins', 'Course Places', 'Course Starts',\n","    'Distance Wins', 'Distance Places', 'Good Wins', 'Good Places', 'Good Starts', ' age',\n","    '1Up Wins', '1Up Places', '1Up Starts', '2Up Wins', '2Up Places', '2Up Starts',\n","    '3Up Wins', '3Up Places', '3Up Starts', '4Up Wins', '4Up Places', '4Up Starts',\n","    'Last Base Rating', 'Last-1 Base Rating', 'Last-1 WFA Rating',\n","    'Joc Ovrl12m Wins', 'Joc Ovrl12m Places',\n","    'Joc Ovrl12m Starts', 'Trn Loc12m Wins', 'Trn Loc12m Places', 'Trn Loc12m Starts',\n","    'Trn Loc5y Wins', 'Trn Loc5y Places', 'Trn Loc5y Starts', 'Trn Ovrl12m Wins',\n","    'Trn Ovrl12m Places', 'Trn Ovrl12m Starts', 'Joc/Trn Wins', 'Joc/Trn Starts',\n","    'Last Dist', 'Last Margin', 'Last Weight', 'Last-1 Dist', 'Last-1 Margin', 'Last-1 Weight',\n","    'Position'\n","]\n","file_path = './2019-WFResultsMerged.csv'\n","data = pd.read_csv(file_path, usecols=columns_to_select, nrows=30000, low_memory=True)\n","\n","display(list(data.columns))\n","print(data.shape)\n","\n","\n"]},{"cell_type":"code","source":["# Remove rows where 'Position' is 99.0\n","data = data[data['Position'] != 99.0]\n","\n","\n","# Display the percentage of missing values in each column before imputation\n","print(\"Percentage of missing values before imputation:\")\n","display((data.isnull().sum() / len(data)) * 100)\n","missing_percentage = (data.isnull().sum() / len(data)) * 100"],"metadata":{"id":"g-q-NndqDvfC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Extract features and target variable\n","X = data.drop('Position', axis=1)\n","y = data['Position']\n","\n","# Perform MICE imputation\n","imputer = IterativeImputer(max_iter=10, random_state=0)\n","X_imputed = imputer.fit_transform(X)\n","\n","# Create a DataFrame with imputed data\n","data_imputed = pd.DataFrame(X_imputed, columns=X.columns)\n","data_imputed['Position'] = y  # Adding the target variable back\n","\n","# Display the percentage of missing values in each column after imputation\n","print(\"\\nPercentage of missing values after imputation:\")\n","print((data_imputed.isnull().sum() / len(data_imputed)) * 100)\n","\n"],"metadata":{"id":"KXRrLFnMDzqj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plot the distribution of 'Position' values\n","plt.figure(figsize=(10, 6))\n","data_imputed['Position'].value_counts().sort_index().plot(kind='bar', color='skyblue')\n","plt.xlabel('Position')\n","plt.ylabel('Count')\n","plt.title('Distribution of Position Values')\n","plt.show()"],"metadata":{"id":"l0wQbt2lD5Bi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Standardize the features\n","scaler = StandardScaler()\n","X_scaled = scaler.fit_transform(X_imputed)\n","\n","print(X_imputed.shape)\n","\n","# Apply PCA\n","pca = PCA(n_components=0.95)  # Choose the explained variance you want to retain\n","X_pca = pca.fit_transform(X_scaled)\n","print(X_pca.shape)\n","# Save PCA model\n","with open('./pca_model.pkl', 'wb') as pca_file:\n","    pickle.dump(pca, pca_file)"],"metadata":{"id":"gkFqtbJpD_Ki"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.05, random_state=42)\n","\n","# Encode the target variable\n","label_encoder = LabelEncoder()\n","y_train_encoded = label_encoder.fit_transform(y_train)\n","y_test_encoded = label_encoder.transform(y_test)\n","\n","# Train and save SVM model\n","svm_model = SVC()\n","svm_model.fit(X_train, y_train_encoded)\n","with open('./svm_model.pkl', 'wb') as svm_file:\n","    pickle.dump(svm_model, svm_file)\n"],"metadata":{"id":"C_qcgPLFD_lq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"72sGkx-uEUqj"},"execution_count":null,"outputs":[]}]}